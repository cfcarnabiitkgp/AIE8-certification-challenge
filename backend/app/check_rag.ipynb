{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG Pipeline - Different Retriever Implementations\n",
    "\n",
    "This notebook demonstrates various retrieval strategies using the VectorStoreService class:\n",
    "1. **Naive/Basic Retriever** - Simple similarity search\n",
    "2. **Contextual Compression with Reranking** - Using Cohere reranker to improve results\n",
    "3. **Multi-Query Retriever** - Generating multiple queries for better coverage\n",
    "4. **Ensemble Retriever** - Combining multiple retrieval methods\n",
    "5. **Parent Document Retriever** - Retrieving larger context chunks\n",
    "6. **Self-Query Retriever** - Query with metadata filtering\n",
    "\n",
    "We'll use PDF documents from the resources directory for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from typing import List, Dict\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.retrievers import (\n",
    "    ContextualCompressionRetriever,\n",
    "    MultiQueryRetriever,\n",
    "    EnsembleRetriever,\n",
    "    ParentDocumentRetriever\n",
    ")\n",
    "from langchain.retrievers.document_compressors import (\n",
    "    LLMChainExtractor,\n",
    "    EmbeddingsFilter\n",
    ")\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Try to import Cohere for reranking (optional)\n",
    "try:\n",
    "    from langchain.retrievers.document_compressors import CohereRerank\n",
    "    COHERE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    COHERE_AVAILABLE = False\n",
    "    print(\"Cohere not available. Install with: pip install cohere\")\n",
    "\n",
    "# Import our custom service\n",
    "from app.services.vector_store import VectorStoreService\n",
    "from app.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Load and Process Documents",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example: Hybrid retriever with filtering and compression\n# Step 1: Use ensemble for diverse results\n# Step 2: Filter by threshold\n# Step 3: Compress with LLM\n\nhybrid_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=ContextualCompressionRetriever(\n        base_compressor=embeddings_filter,\n        base_retriever=ensemble_retriever\n    )\n)\n\nhybrid_results = hybrid_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"HYBRID RETRIEVER (Ensemble + Filter + Compression)\")\nprint(\"=\" * 80)\nprint(f\"Retrieved {len(hybrid_results)} documents\\n\")\nfor i, doc in enumerate(hybrid_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content}\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Extending Retrievers - Custom Example\n\nYou can combine multiple techniques to create custom retrievers tailored to your needs.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\n### Retriever Comparison:\n\n1. **Basic Retriever**: Fast and simple, good baseline\n2. **Contextual Compression (LLM)**: More precise but slower, extracts only relevant parts\n3. **Embeddings Filter**: Fast filtering based on similarity threshold\n4. **Cohere Rerank**: Best quality but requires API, excellent for reordering results\n5. **Multi-Query**: Better coverage through query expansion\n6. **Ensemble**: Combines semantic and keyword search for robustness\n7. **Parent Document**: Good for returning larger context\n8. **MMR**: Best for diverse results, avoids redundancy\n\n### Recommendations:\n- **For speed**: Basic or Embeddings Filter\n- **For quality**: Cohere Rerank or Contextual Compression\n- **For coverage**: Multi-Query or Ensemble\n- **For diversity**: MMR\n- **For context**: Parent Document Retriever\n\n### Key Takeaways:\n- Different retrievers excel at different tasks\n- Ensemble methods often provide the best balance\n- Consider your use case: speed vs quality vs coverage\n- The VectorStoreService class provides a simple interface for basic retrieval\n- Advanced retrievers can significantly improve RAG performance",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compare RAG chains\nrag_chains = {\n    \"Basic RAG\": create_rag_chain(basic_retriever),\n    \"Compressed RAG\": create_rag_chain(compression_retriever),\n    \"Ensemble RAG\": create_rag_chain(ensemble_retriever),\n    \"Multi-Query RAG\": create_rag_chain(multiquery_retriever),\n}\n\nprint(\"=\" * 80)\nprint(\"RAG CHAIN COMPARISON\")\nprint(\"=\" * 80)\nprint(f\"Question: {test_question}\\n\")\n\nfor name, chain in rag_chains.items():\n    print(\"\\n\" + \"=\" * 80)\n    print(name)\n    print(\"=\" * 80)\n    \n    try:\n        result = chain.invoke({\"query\": test_question})\n        print(f\"\\nAnswer: {result['result']}\")\n        print(f\"\\nSources: {len(result['source_documents'])} documents\")\n        for i, doc in enumerate(result['source_documents'][:2], 1):\n            print(f\"  [{i}] {doc.metadata.get('source', 'Unknown')}\")\n    except Exception as e:\n        print(f\"Error: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\n\n# RAG prompt\ntemplate = \"\"\"Use the following context to answer the question.\nIf you don't know, say so.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n\nQA_PROMPT = PromptTemplate(\n    template=template,\n    input_variables=[\"context\", \"question\"]\n)\n\ndef create_rag_chain(retriever):\n    return RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=\"stuff\",\n        retriever=retriever,\n        return_source_documents=True,\n        chain_type_kwargs={\"prompt\": QA_PROMPT}\n    )\n\ntest_question = \"What are the most important principles for writing clear mathematical papers?\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Complete RAG Chain\n\nBuilding end-to-end RAG pipelines with different retrievers.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Similarity search\nquery = \"What are best practices for mathematical writing?\"\nresults = await vector_service.similarity_search(query, k=5)\n\nprint(\"=\" * 80)\nprint(\"VectorStoreService RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Query: {query}\\n\")\n\nfor i, result in enumerate(results, 1):\n    print(f\"\\n[{i}] Score: {result['score']:.4f}\")\n    print(f\"Source: {result['metadata'].get('source', 'Unknown')}\")\n    print(f\"Content: {result['text'][:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Initialize service\nvector_service = VectorStoreService()\n\n# Process PDFs\nprint(\"Processing PDFs with VectorStoreService...\")\ntotal_chunks = 0\n\nfor pdf_path in pdf_files:\n    metadata = {\"source\": pdf_path.name}\n    chunk_count = await vector_service.process_pdf(str(pdf_path), metadata)\n    total_chunks += chunk_count\n    print(f\"  {pdf_path.name}: {chunk_count} chunks\")\n\nprint(f\"\\nTotal: {total_chunks} chunks indexed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Using VectorStoreService Class\n\nDemonstrates how to use the custom VectorStoreService class from the repository.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_queries = [\n    \"What are the key principles of mathematical writing?\",\n    \"How should one structure a mathematical proof?\",\n    \"What is the importance of clarity in technical writing?\",\n]\n\nretrievers_to_compare = {\n    \"Basic\": basic_retriever,\n    \"Compressed\": compression_retriever,\n    \"Filter\": filter_retriever,\n    \"Multi-Query\": multiquery_retriever,\n    \"Ensemble\": ensemble_retriever,\n    \"MMR\": mmr_retriever,\n}\n\nprint(\"=\" * 80)\nprint(\"RETRIEVER COMPARISON\")\nprint(\"=\" * 80)\n\nfor query in test_queries:\n    print(f\"\\n\\nQuery: {query}\")\n    print(\"-\" * 80)\n    \n    for name, retriever in retrievers_to_compare.items():\n        try:\n            results = retriever.invoke(query)\n            print(f\"{name:15} -> {len(results)} documents\")\n        except Exception as e:\n            print(f\"{name:15} -> Error: {str(e)[:40]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Comparison Across Multiple Queries",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "mmr_retriever = vectorstore.as_retriever(\n    search_type=\"mmr\",\n    search_kwargs={\n        \"k\": 5,\n        \"fetch_k\": 20,\n        \"lambda_mult\": 0.5\n    }\n)\n\nmmr_results = mmr_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"MMR RETRIEVER RESULTS\")\nprint(\"=\" * 80)\nfor i, doc in enumerate(mmr_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. MMR (Maximum Marginal Relevance)\n\nBalances relevance and diversity in results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "parent_results = parent_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"PARENT DOCUMENT RETRIEVER RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Retrieved {len(parent_results)} parent documents\\n\")\nfor i, doc in enumerate(parent_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Length: {len(doc.page_content)} chars\")\n    print(f\"Preview: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Parent and child splitters\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n\n# Store for parents\nstore = InMemoryStore()\n\n# Child vector store\nchild_vectorstore = Qdrant.from_documents(\n    [],\n    embeddings,\n    collection_name=\"child_chunks\",\n    client=qdrant_client,\n    force_recreate=True\n)\n\n# Parent retriever\nparent_retriever = ParentDocumentRetriever(\n    vectorstore=child_vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n\nparent_retriever.add_documents(all_documents)\nprint(f\"Store contains {len(store.store)} parent documents\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Parent Document Retriever\n\nRetrieves small chunks for similarity but returns larger parent documents for context.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# BM25 retriever (keyword-based)\nbm25_retriever = BM25Retriever.from_documents(chunks)\nbm25_retriever.k = 5\n\n# Ensemble retriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[basic_retriever, bm25_retriever],\n    weights=[0.5, 0.5]\n)\n\nensemble_results = ensemble_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"ENSEMBLE RETRIEVER RESULTS\")\nprint(\"=\" * 80)\nfor i, doc in enumerate(ensemble_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Ensemble Retriever\n\nCombines vector search + BM25 keyword search using Reciprocal Rank Fusion.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import logging\nlogging.basicConfig()\nlogging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n\nmultiquery_retriever = MultiQueryRetriever.from_llm(\n    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n    llm=llm\n)\n\nmultiquery_results = multiquery_retriever.invoke(TEST_QUERY)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"MULTI-QUERY RETRIEVER RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Retrieved {len(multiquery_results)} unique documents\\n\")\nfor i, doc in enumerate(multiquery_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Multi-Query Retriever\n\nGenerates multiple query variations for better coverage.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if COHERE_AVAILABLE and os.getenv(\"COHERE_API_KEY\"):\n    cohere_reranker = CohereRerank(\n        model=\"rerank-english-v2.0\",\n        top_n=5\n    )\n    \n    rerank_retriever = ContextualCompressionRetriever(\n        base_compressor=cohere_reranker,\n        base_retriever=vectorstore.as_retriever(search_kwargs={\"k\": 20})\n    )\n    \n    reranked_results = rerank_retriever.invoke(TEST_QUERY)\n    \n    print(\"=\" * 80)\n    print(\"COHERE RERANK RESULTS\")\n    print(\"=\" * 80)\n    for i, doc in enumerate(reranked_results, 1):\n        print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n        print(f\"Score: {doc.metadata.get('relevance_score', 'N/A')}\")\n        print(f\"Content: {doc.page_content[:300]}...\")\n        print(\"-\" * 80)\nelse:\n    print(\"Cohere not available or no API key set\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Cohere Rerank (Optional)\n\nUses Cohere's reranking model if available.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Embeddings filter\nembeddings_filter = EmbeddingsFilter(\n    embeddings=embeddings,\n    similarity_threshold=0.76\n)\n\nfilter_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter,\n    base_retriever=vectorstore.as_retriever(search_kwargs={\"k\": 10})\n)\n\nfiltered_results = filter_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"EMBEDDINGS FILTER RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Retrieved {len(filtered_results)} documents after filtering\\n\")\nfor i, doc in enumerate(filtered_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Embeddings Filter\n\nFilters based on similarity threshold.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# LLM chain extractor\ncompressor = LLMChainExtractor.from_llm(llm)\n\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=basic_retriever\n)\n\ncompressed_results = compression_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"CONTEXTUAL COMPRESSION RESULTS\")\nprint(\"=\" * 80)\nfor i, doc in enumerate(compressed_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content}\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Contextual Compression with LLM\n\nUses LLM to extract only relevant parts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Basic retriever\nbasic_retriever = vectorstore.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": 5}\n)\n\n# Retrieve documents\nbasic_results = basic_retriever.invoke(TEST_QUERY)\n\nprint(\"=\" * 80)\nprint(\"BASIC RETRIEVER RESULTS\")\nprint(\"=\" * 80)\nfor i, doc in enumerate(basic_results, 1):\n    print(f\"\\n[{i}] Source: {doc.metadata.get('source', 'Unknown')}\")\n    print(f\"Content: {doc.page_content[:300]}...\")\n    print(\"-\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Naive/Basic Retriever\n\nSimple similarity search on embeddings.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize LLM\nllm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n\n# Test query\nTEST_QUERY = \"What are the key principles of mathematical writing?\"\nprint(f\"Test Query: {TEST_QUERY}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Initialize embeddings\nembeddings = OpenAIEmbeddings(\n    model=settings.embedding_model,\n    openai_api_key=settings.openai_api_key\n)\n\n# Initialize Qdrant\nqdrant_client = QdrantClient(\n    host=settings.qdrant_host,\n    port=settings.qdrant_port\n)\n\n# Create vector store\ncollection_name = \"rag_test_collection\"\n\nvectorstore = Qdrant.from_documents(\n    chunks,\n    embeddings,\n    collection_name=collection_name,\n    client=qdrant_client,\n    force_recreate=True\n)\n\nprint(f\"Vector store created with {len(chunks)} documents\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Initialize Vector Store",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Split into chunks\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    length_function=len\n)\n\nchunks = text_splitter.split_documents(all_documents)\nprint(f\"Created {len(chunks)} chunks\")\nprint(f\"\\nExample chunk:\")\nprint(f\"Content: {chunks[0].page_content[:200]}...\")\nprint(f\"Metadata: {chunks[0].metadata}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load all PDFs\nall_documents = []\n\nfor pdf_path in pdf_files:\n    loader = PyPDFLoader(str(pdf_path))\n    docs = loader.load()\n    for doc in docs:\n        doc.metadata[\"source\"] = pdf_path.name\n    all_documents.extend(docs)\n\nprint(f\"Loaded {len(all_documents)} pages total\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Define resources directory\nRESOURCES_DIR = Path(\"resources\")\n\n# List available PDFs\npdf_files = list(RESOURCES_DIR.glob(\"*.pdf\"))\nprint(f\"Found {len(pdf_files)} PDF files:\")\nfor pdf in pdf_files:\n    print(f\"  - {pdf.name}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}